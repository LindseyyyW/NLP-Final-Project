{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5838f5ee",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:28.043116Z",
          "iopub.status.busy": "2024-03-13T04:34:28.042732Z",
          "iopub.status.idle": "2024-03-13T04:34:28.773040Z",
          "shell.execute_reply": "2024-03-13T04:34:28.772011Z"
        },
        "papermill": {
          "duration": 0.7405,
          "end_time": "2024-03-13T04:34:28.775407",
          "exception": false,
          "start_time": "2024-03-13T04:34:28.034907",
          "status": "completed"
        },
        "tags": [],
        "id": "5838f5ee",
        "outputId": "6dcbcf06-75a9-411c-ca3a-d0bd80df3df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/checkpoints/checkpointspytorch_model.bin\n",
            "/kaggle/input/checkpoints/results/lr_0.0001_seed_1_bs_8_ga_1_layer_num_1_alpha_0.5_beta_1/dev.csv\n",
            "/kaggle/input/openbkqa/dev.jsonl\n",
            "/kaggle/input/openbkqa/test.jsonl\n",
            "/kaggle/input/openbkqa/train.jsonl\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6820471",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:28.788373Z",
          "iopub.status.busy": "2024-03-13T04:34:28.787969Z",
          "iopub.status.idle": "2024-03-13T04:34:42.362867Z",
          "shell.execute_reply": "2024-03-13T04:34:42.361926Z"
        },
        "papermill": {
          "duration": 13.583991,
          "end_time": "2024-03-13T04:34:42.365365",
          "exception": false,
          "start_time": "2024-03-13T04:34:28.781374",
          "status": "completed"
        },
        "tags": [],
        "id": "b6820471",
        "outputId": "292fed87-9093-467b-d3c8-08ca09c4c694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge\r\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\r\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\r\n",
            "Installing collected packages: rouge\r\n",
            "Successfully installed rouge-1.0.1\r\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "679407d3",
      "metadata": {
        "papermill": {
          "duration": 0.005739,
          "end_time": "2024-03-13T04:34:42.377264",
          "exception": false,
          "start_time": "2024-03-13T04:34:42.371525",
          "status": "completed"
        },
        "tags": [],
        "id": "679407d3"
      },
      "source": [
        "**utils.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cef4241",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:42.391369Z",
          "iopub.status.busy": "2024-03-13T04:34:42.390340Z",
          "iopub.status.idle": "2024-03-13T04:34:45.978649Z",
          "shell.execute_reply": "2024-03-13T04:34:45.977658Z"
        },
        "papermill": {
          "duration": 3.598019,
          "end_time": "2024-03-13T04:34:45.980965",
          "exception": false,
          "start_time": "2024-03-13T04:34:42.382946",
          "status": "completed"
        },
        "tags": [],
        "id": "1cef4241"
      },
      "outputs": [],
      "source": [
        "#coding=utf-8\n",
        "import rouge\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "rouge = rouge.Rouge()\n",
        "def compute_rouge(source, target):\n",
        "\n",
        "    source, target = ' '.join(source), ' '.join(target)\n",
        "    try:\n",
        "        scores = rouge.get_scores(hyps=source, refs=target)\n",
        "        return {\n",
        "            'rouge-1': scores[0]['rouge-1']['f'],\n",
        "            'rouge-2': scores[0]['rouge-2']['f'],\n",
        "            'rouge-l': scores[0]['rouge-l']['f'],\n",
        "        }\n",
        "    except ValueError:\n",
        "        return {\n",
        "            'rouge-1': 0.0,\n",
        "            'rouge-2': 0.0,\n",
        "            'rouge-l': 0.0,\n",
        "        }\n",
        "\n",
        "\n",
        "def compute_rouges(sources, targets):\n",
        "    scores = {\n",
        "        'rouge-1': 0.0,\n",
        "        'rouge-2': 0.0,\n",
        "        'rouge-l': 0.0,\n",
        "    }\n",
        "    for source, target in zip(sources, targets):\n",
        "        score = compute_rouge(source, target)\n",
        "        for k, v in scores.items():\n",
        "            scores[k] = v + score[k]\n",
        "    return {k: v / len(targets) for k, v in scores.items()}\n",
        "\n",
        "\n",
        "def save_dataset(path, dataset):\n",
        "\n",
        "    with open(path, 'w', encoding='utf-8') as f:\n",
        "        for sample in dataset:\n",
        "            f.write(sample + '\\n')\n",
        "\n",
        "\n",
        "def read_dataset(path):\n",
        "    dataset = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        for i, line in enumerate(lines):\n",
        "            # if i > 10:\n",
        "            #     break\n",
        "            line = line.strip()\n",
        "            line = json.loads(line)\n",
        "            dataset.append(line)\n",
        "    return dataset\n",
        "\n",
        "def save_model(output_model_file, model, optimizer):\n",
        "    os.makedirs(output_model_file, exist_ok=True)\n",
        "    output_model_file += 'pytorch_model.bin'\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, output_model_file)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)  # cpu\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # gpu\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True  # consistent results on the cpu and gpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f4a249",
      "metadata": {
        "papermill": {
          "duration": 0.005833,
          "end_time": "2024-03-13T04:34:45.993165",
          "exception": false,
          "start_time": "2024-03-13T04:34:45.987332",
          "status": "completed"
        },
        "tags": [],
        "id": "41f4a249"
      },
      "source": [
        "**modeling_transformer.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a9fe0f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:46.007272Z",
          "iopub.status.busy": "2024-03-13T04:34:46.006749Z",
          "iopub.status.idle": "2024-03-13T04:34:46.099977Z",
          "shell.execute_reply": "2024-03-13T04:34:46.099267Z"
        },
        "papermill": {
          "duration": 0.103101,
          "end_time": "2024-03-13T04:34:46.102073",
          "exception": false,
          "start_time": "2024-03-13T04:34:45.998972",
          "status": "completed"
        },
        "tags": [],
        "id": "a0a9fe0f",
        "outputId": "74fba9ee-ec92-4d21-cdc1-38f030ccf918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ]
        }
      ],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors and The HugginFace Inc. team.\n",
        "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless requreader2d by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"PyTorch BERT model.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import math\n",
        "import logging\n",
        "import tarfile\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
        "    'bert-base-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\",\n",
        "    'bert-large-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz\",\n",
        "    'bert-base-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz\",\n",
        "    'bert-large-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz\",\n",
        "    'bert-base-multilingual-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz\",\n",
        "    'bert-base-multilingual-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz\",\n",
        "    'bert-base-chinese': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz\",\n",
        "}\n",
        "CONFIG_NAME = 'bert_config.json'\n",
        "WEIGHTS_NAME = 'pytorch_model.bin'\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"Implementation of the gelu activation function.\n",
        "        For information: OpenAI GPT's gelu is slightly diffretrievernt (and gives slightly diffretrievernt results):\n",
        "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
        "\n",
        "\n",
        "class BertConfig(object):\n",
        "    \"\"\"Configuration class to store the configuration of a `BertModel`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size_or_config_json_file,\n",
        "                 hidden_size=768,\n",
        "                 num_hidden_layers=12,\n",
        "                 num_attention_heads=12,\n",
        "                 intermediate_size=3072,\n",
        "                 hidden_act=\"gelu\",\n",
        "                 hidden_dropout_prob=0.2,\n",
        "                 attention_probs_dropout_prob=0.2,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02):\n",
        "        \"\"\"Constructs BertConfig.\n",
        "\n",
        "        Args:\n",
        "            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n",
        "            hidden_size: Size of the encoder layers and the pooler layer.\n",
        "            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
        "            num_attention_heads: Number of attention heads for each attention layer in\n",
        "                the Transformer encoder.\n",
        "            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n",
        "                layer in the Transformer encoder.\n",
        "            hidden_act: The non-linear activation function (function or string) in the\n",
        "                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n",
        "            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n",
        "                layers in the embeddings, encoder, and pooler.\n",
        "            attention_probs_dropout_prob: The dropout ratio for the attention\n",
        "                probabilities.\n",
        "            max_position_embeddings: The maximum sequence length that this model might\n",
        "                ever be used with. Typically set this to something large just in case\n",
        "                (e.g., 512 or 1024 or 2048).\n",
        "            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n",
        "                `BertModel`.\n",
        "            initializer_range: The sttdev of the truncated_normal_initializer for\n",
        "                initializing all weight matrices.\n",
        "        \"\"\"\n",
        "        if isinstance(vocab_size_or_config_json_file, str):\n",
        "            with open(vocab_size_or_config_json_file, \"r\", encoding='utf-8') as reader:\n",
        "                json_config = json.loads(reader.read())\n",
        "            for key, value in json_config.items():\n",
        "                self.__dict__[key] = value\n",
        "        elif isinstance(vocab_size_or_config_json_file, int):\n",
        "            self.vocab_size = vocab_size_or_config_json_file\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_hidden_layers = num_hidden_layers\n",
        "            self.num_attention_heads = num_attention_heads\n",
        "            self.hidden_act = hidden_act\n",
        "            self.intermediate_size = intermediate_size\n",
        "            self.hidden_dropout_prob = hidden_dropout_prob\n",
        "            self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "            self.max_position_embeddings = max_position_embeddings\n",
        "            self.type_vocab_size = type_vocab_size\n",
        "            self.initializer_range = initializer_range\n",
        "        else:\n",
        "            raise ValueError(\"First argument must be either a vocabulary size (int)\"\n",
        "                             \"or the path to a pretrained model config file (str)\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, json_object):\n",
        "        \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"\n",
        "        config = BertConfig(vocab_size_or_config_json_file=-1)\n",
        "        for key, value in json_object.items():\n",
        "            config.__dict__[key] = value\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_json_file(cls, json_file):\n",
        "        \"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\n",
        "        with open(json_file, \"r\", encoding='utf-8') as reader:\n",
        "            text = reader.read()\n",
        "        return cls.from_dict(json.loads(text))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "try:\n",
        "    from apex.normalization.fused_layer_norm import FusedLayerNorm as BertLayerNorm\n",
        "except ImportError:\n",
        "    print(\"Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\")\n",
        "\n",
        "\n",
        "    class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias\n",
        "\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
        "        # any TensorFlow checkpoint file\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfAttention, self).__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        query_layer_hat = torch.nn.functional.normalize(query_layer, dim=-1)\n",
        "        key_layer_hat = torch.nn.functional.normalize(key_layer, dim=-1)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer_hat, key_layer_hat.transpose(-1, -2))\n",
        "\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        #attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        #attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        attention_softmax = attention_scores\n",
        "\n",
        "        # This is actually dropping out entreader2 tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_scores)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        B, n_head, n_tok, n_embd = query_layer.shape\n",
        "        context_layer /= n_embd\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        return context_layer, attention_softmax\n",
        "\n",
        "    # def forward(self, hidden_states, attention_mask):\n",
        "    #     mixed_query_layer = self.query(hidden_states)\n",
        "    #     mixed_key_layer = self.key(hidden_states)\n",
        "    #     mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "    #     query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "    #     key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "    #     value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "    #     query_layer_hat = torch.nn.functional.normalize(query_layer, dim = -2)\n",
        "    #     key_layer_hat = torch.nn.functional.normalize(key_layer, dim = -2)\n",
        "\n",
        "    #     attention_scores = torch.matmul(key_layer_hat.transpose(-1, -2), value_layer)\n",
        "\n",
        "    #     # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "    #    #attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "    #     attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "    #     # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "    #     attention_scores = attention_scores + attention_mask\n",
        "    #     # Normalize the attention scores to probabilities.\n",
        "    #     #attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "    #     #attention_softmax = attention_probs\n",
        "\n",
        "    #     # This is actually dropping out entreader2 tokens to attend to, which might\n",
        "    #     # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "    #     #attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "    #     context_layer = torch.matmul(query_layer_hat, attention_scores)\n",
        "    #     B, n_tok, n_embd = query_layer.size()\n",
        "    #     attention_scores = context_layer / n_embd\n",
        "\n",
        "    #     context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "    #     new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "    #     context_layer = context_layer.view(*new_context_layer_shape)\n",
        "    #     return context_layer, attention_scores\n",
        "\n",
        "\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask):\n",
        "        self_output, attention_probs = self.self(input_tensor, attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output, attention_probs\n",
        "\n",
        "\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertIntermediate, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = ACT2FN[config.hidden_act] \\\n",
        "            if isinstance(config.hidden_act, str) else config.hidden_act\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertLayer, self).__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        attention_output, attention_probs = self.attention(hidden_states, attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output, attention_probs\n",
        "\n",
        "\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__()\n",
        "        layer = BertLayer(config)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            hidden_states, attention_probs = layer_module(hidden_states, attention_mask)\n",
        "\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append(hidden_states)\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "        return all_encoder_layers\n",
        "\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPooler, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "class BertPredictionHeadTransform(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPredictionHeadTransform, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.transform_act_fn = ACT2FN[config.hidden_act] \\\n",
        "            if isinstance(config.hidden_act, str) else config.hidden_act\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.transform_act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertLMPredictionHead(nn.Module):\n",
        "    def __init__(self, config, bert_model_embedding_weights):\n",
        "        super(BertLMPredictionHead, self).__init__()\n",
        "        self.transform = BertPredictionHeadTransform(config)\n",
        "\n",
        "        # The output weights are the same as the input embeddings, but thretriever is\n",
        "        # an output-only bias for each token.\n",
        "        self.decoder = nn.Linear(bert_model_embedding_weights.size(1),\n",
        "                                 bert_model_embedding_weights.size(0),\n",
        "                                 bias=False)\n",
        "        self.decoder.weight = bert_model_embedding_weights\n",
        "        self.bias = nn.Parameter(torch.zeros(bert_model_embedding_weights.size(0)))\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        hidden_states = self.decoder(hidden_states) + self.bias\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertOnlyMLMHead(nn.Module):\n",
        "    def __init__(self, config, bert_model_embedding_weights):\n",
        "        super(BertOnlyMLMHead, self).__init__()\n",
        "        self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        return prediction_scores\n",
        "\n",
        "\n",
        "class BertOnlyNSPHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertOnlyNSPHead, self).__init__()\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, pooled_output):\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return seq_relationship_score\n",
        "\n",
        "\n",
        "class BertPreTrainingHeads(nn.Module):\n",
        "    def __init__(self, config, bert_model_embedding_weights):\n",
        "        super(BertPreTrainingHeads, self).__init__()\n",
        "        self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, sequence_output, pooled_output):\n",
        "        prediction_scores = self.predictions(sequence_output)\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)\n",
        "        return prediction_scores, seq_relationship_score\n",
        "\n",
        "class MyTransformer(nn.Module):\n",
        "    def __init__(self, dim, num_attention_heads, num_hidden_layers):\n",
        "        super(MyTransformer, self).__init__()\n",
        "        config = Config()\n",
        "        config.num_hidden_layers = num_hidden_layers\n",
        "        config.hidden_size = dim\n",
        "        config.num_attention_heads = num_attention_heads\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "\n",
        "    def forward(self, embedding_output, attention_mask, output_all_encoded_layers=False):\n",
        "\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        encoded_layers = self.encoder(embedding_output,\n",
        "                                      extended_attention_mask,\n",
        "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "        return encoded_layers, pooled_output\n",
        "\n",
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.attention_probs_dropout_prob = 0.2\n",
        "        self.hidden_act = \"relu\"\n",
        "        self.hidden_dropout_prob = 0.2\n",
        "        self.hidden_size = 768\n",
        "        self.initializer_range = 0.02\n",
        "        self.max_position_embeddings = 513\n",
        "        self.num_attention_heads = 16\n",
        "        # self.num_attention_heads = 12\n",
        "        # self.num_attention_heads = 8\n",
        "        self.num_hidden_layers = 1\n",
        "        self.type_vocab_size = 2\n",
        "        self.layer_norm_eps = 1e-05\n",
        "        self.intermediate_size = 3072\n",
        "\n",
        "class MultiModalMapping(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(MultiModalMapping, self).__init__()\n",
        "        self.dense = nn.Linear(dim, dim * 4)\n",
        "        self.dense_output = nn.Linear(dim * 4, dim)\n",
        "        self.intermediate_act_fn = ACT2FN['relu']\n",
        "        self.LayerNorm = BertLayerNorm(dim, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states0 = hidden_states\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        hidden_states = self.dense_output(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + hidden_states0)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "    # def __init__(self, dim):\n",
        "    #     super(MultiModalMapping, self).__init__()\n",
        "    #     self.fc1 = nn.Linear(dim, 4*dim)\n",
        "    #     self.fc2 = nn.Linear(4*dim, dim)\n",
        "    #     self.fc3 = nn.Linear(dim, dim)\n",
        "    #     self.fc4 = nn.Linear(dim, dim)\n",
        "    #     self.relu = nn.ReLU()\n",
        "    #     self.layer_norm = BertLayerNorm(dim)\n",
        "    #     self.dropout = nn.Dropout(0.5)\n",
        "    #     # nn.Conv1d(in_channels=dim, out_channels=dim, kernel_size=)\n",
        "    #     self.fake_conv = nn.Linear(3, 1)\n",
        "    #\n",
        "    #\n",
        "    # def forward(self, hidden_states):\n",
        "    #     hidden_states = self.layer_norm(hidden_states)\n",
        "    #     h1 = self.fc1(hidden_states)\n",
        "    #     h1 = self.dropout(h1)\n",
        "    #     h2 = self.layer_norm(self.fc2(h1))\n",
        "    #     # h3 = self.layer_norm(self.fc3(h2))\n",
        "    #     # h4 = self.layer_norm(self.fc4(h3))\n",
        "    #     h = self.relu(h2)\n",
        "    #     return h\n",
        "    #     # stack = torch.cat([h2.unsqueeze(dim=-1), h3.unsqueeze(dim=-1), h4.unsqueeze(dim=-1)], dim=3)\n",
        "    #     # h = self.fake_conv(stack)\n",
        "    #     # h = h.view(h.size(0), h.size(1), h.size(2))\n",
        "    #     # h = self.relu(h)\n",
        "    #     # return h\n",
        "\n",
        "\n",
        "class SemanticMatch(nn.Module):\n",
        "    def __init__(self, dim, layer_num):\n",
        "        super(SemanticMatch, self).__init__()\n",
        "        dpda_layer = DPDALayear(dim)\n",
        "        self.q_o = nn.ModuleList([copy.deepcopy(dpda_layer) for _ in range(layer_num)])\n",
        "        self.linear = nn.Linear(2 * dim, dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, q, o, mask_q, mask_o):\n",
        "        for layer_module in self.q_o:\n",
        "            q, o, q_weight, o_weight = layer_module(q, o, mask_q, mask_o)\n",
        "        q, _ = torch.max(q, dim=1)\n",
        "        o, _ = torch.max(o, dim=1)\n",
        "        q_o = self.get_vector(q, o)\n",
        "        return q_o, q_weight, o_weight\n",
        "\n",
        "    def get_vector(self, v1, v2):\n",
        "        p_b = torch.cat([v1, v2], dim=1)  # 2*dim\n",
        "        p_b = self.linear(p_b)  # dim\n",
        "        p_b = self.relu(p_b)\n",
        "        return p_b\n",
        "\n",
        "\n",
        "class DPDALayear(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(DPDALayear, self).__init__()\n",
        "        self.W_p = nn.Linear(2 * dim, dim)\n",
        "        self.W_q = nn.Linear(2 * dim, dim)\n",
        "        self.W_map = nn.Linear(dim, dim)\n",
        "\n",
        "\n",
        "    def forward(self, P, Q, p_mask=None, q_mask=None):\n",
        "        # P = self.W_map(P)\n",
        "        P_ori = P\n",
        "        Q_ori = Q\n",
        "        A = torch.matmul(P, Q.transpose(dim0=1, dim1=2))  # batch, l_p, l_q\n",
        "\n",
        "        if p_mask is not None:\n",
        "            p_mask = p_mask.float()\n",
        "            p_mask = 1 - p_mask\n",
        "            p_mask = p_mask * -10000.0\n",
        "            p_mask = p_mask.unsqueeze(dim=2)\n",
        "            p_mask = p_mask.expand_as(A)\n",
        "            A = A + p_mask\n",
        "            A = A.to(P.dtype)\n",
        "\n",
        "        if q_mask is not None:\n",
        "            q_mask = q_mask.float()\n",
        "            q_mask = 1 - q_mask\n",
        "            q_mask = q_mask * -10000.0\n",
        "            q_mask = q_mask.unsqueeze(dim=1)\n",
        "            q_mask = q_mask.expand_as(A)\n",
        "            A = A + q_mask\n",
        "            A = A.to(Q.dtype)\n",
        "\n",
        "        p_weight, _ = torch.max(A, dim=2)\n",
        "        q_weight, _ = torch.max(A, dim=1)\n",
        "        # if p_mask is not None:\n",
        "        #     p_weight *= p_mask\n",
        "        # if q_mask is not None:\n",
        "        #     q_weight *= q_mask\n",
        "\n",
        "\n",
        "        A_q = torch.softmax(A, dim=2)  # l_p, l_q\n",
        "        A_p = torch.softmax(A.transpose(dim0=1, dim1=2), dim=2)  # l_q, l_p\n",
        "\n",
        "        P_q = torch.matmul(A_q, Q)  # l_p, dim\n",
        "        Q_p = torch.matmul(A_p, P)  # l_q, dim\n",
        "\n",
        "        P_t = torch.cat([P_q, P], dim=2)  # l_p, 2*dim\n",
        "        Q_t = torch.cat([Q_p, Q], dim=2)  # l_q, 2*dim\n",
        "\n",
        "        Q = torch.matmul(A_p, P_t)  # l_q, 2*dim\n",
        "        P = torch.matmul(A_q, Q_t)  # l_p, 2*dim\n",
        "        P = P_ori + self.W_p(P)  # l_p, dim\n",
        "        layer_norm = nn.LayerNorm(normalized_shape=[P.size(-2), P.size(-1)],elementwise_affine=False)\n",
        "        P = layer_norm(P)\n",
        "        Q = Q_ori + self.W_q(Q)  # l_q, dim\n",
        "        layer_norm = nn.LayerNorm(normalized_shape=[Q.size(-2), Q.size(-1)],elementwise_affine=False)\n",
        "        Q = layer_norm(Q)\n",
        "        return P, Q, p_weight, q_weight\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4357861",
      "metadata": {
        "papermill": {
          "duration": 0.005652,
          "end_time": "2024-03-13T04:34:46.113676",
          "exception": false,
          "start_time": "2024-03-13T04:34:46.108024",
          "status": "completed"
        },
        "tags": [],
        "id": "c4357861"
      },
      "source": [
        "**modeling_genmc.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18c438a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:46.127285Z",
          "iopub.status.busy": "2024-03-13T04:34:46.126945Z",
          "iopub.status.idle": "2024-03-13T04:34:49.551106Z",
          "shell.execute_reply": "2024-03-13T04:34:49.550348Z"
        },
        "papermill": {
          "duration": 3.433789,
          "end_time": "2024-03-13T04:34:49.553412",
          "exception": false,
          "start_time": "2024-03-13T04:34:46.119623",
          "status": "completed"
        },
        "tags": [],
        "id": "18c438a2"
      },
      "outputs": [],
      "source": [
        "#coding=utf-8\n",
        "from transformers import T5ForConditionalGeneration\n",
        "from transformers.file_utils import ModelOutput\n",
        "import torch\n",
        "#from .modeling_transformer import MyTransformer, SexnticMatch\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "class GenMC(nn.Module):\n",
        "    def __init__(self, model_path, num_hidden_layers, alpha, beta):\n",
        "        super(GenMC, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        self.t5_model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "        dim = self.t5_model.config.d_model\n",
        "        self.option_linear = nn.Linear(dim, 1).to(device)\n",
        "        self.option_linear.device = device\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.semantic_matching = SemanticMatch(dim, num_hidden_layers).to(device)\n",
        "        self.semantic_matching.device = device\n",
        "        num_attention_heads = dim // 64    #original: // 64\n",
        "        self.transformer_laryer_de = MyTransformer(dim, num_attention_heads, num_hidden_layers).to(device)\n",
        "        self.transformer_laryer_de.device = device\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        n_gpu = torch.cuda.device_count()\n",
        "        layer_num = self.t5_model.config.num_layers\n",
        "        layer_per_gpu = layer_num // n_gpu\n",
        "        layer_per_gpu_remainder = layer_num % n_gpu\n",
        "        device_map = {}\n",
        "        cur_layer = 0\n",
        "        for n in range(n_gpu):\n",
        "            device_map[n] = []\n",
        "            if n < layer_per_gpu_remainder:\n",
        "                layer_assigned = layer_per_gpu+1\n",
        "            else:\n",
        "                layer_assigned = layer_per_gpu\n",
        "\n",
        "            for i in range(layer_assigned):\n",
        "                device_map[n].append(cur_layer)\n",
        "                cur_layer += 1\n",
        "        self.t5_model.parallelize(device_map)\n",
        "\n",
        "\n",
        "    def forward(self, q_ids, q_mask, qo_ids, qo_mask, choice_num, clue_ids=None, clue_content_ids=None, clue_content_mask=None, answers=None):\n",
        "        self.choice_num = choice_num\n",
        "        if answers is not None and clue_ids is not None and clue_content_ids is not None and clue_content_mask is not None:\n",
        "            opt_score, output_sequences = self.get_option_score(q_ids, q_mask, qo_ids, qo_mask)\n",
        "            local_device = self.t5_model.device\n",
        "            t5_output = self.t5_model(input_ids=clue_content_ids.to(local_device), attention_mask=clue_content_mask.to(local_device),\n",
        "                                      labels=clue_ids.to(local_device))\n",
        "            loss_ans = t5_output.loss\n",
        "            loss = self.criterion(opt_score, answers)\n",
        "            return self.alpha * loss + self.beta * loss_ans\n",
        "        else:\n",
        "            opt_score, output_sequences = self.get_option_score(q_ids, q_mask, qo_ids, qo_mask)\n",
        "            return opt_score, output_sequences\n",
        "\n",
        "    def get_option_score(self, q_ids, q_mask, qo_ids, qo_mask):\n",
        "        local_device = self.t5_model.encoder.device\n",
        "        t5_output = self.t5_model.encoder(input_ids=qo_ids.to(local_device), attention_mask=qo_mask.to(local_device))\n",
        "        encoder_qo = t5_output[0]\n",
        "\n",
        "        t5_output = self.t5_model.encoder(input_ids=q_ids.to(local_device), attention_mask=q_mask.to(local_device))\n",
        "        encoder_q = t5_output[0]\n",
        "        local_device = self.t5_model.device\n",
        "        t5_output = self.t5_model.generate(\n",
        "            encoder_outputs=ModelOutput(last_hidden_state=encoder_q.to(local_device)),\n",
        "            attention_mask=q_mask.to(local_device),\n",
        "            do_sample=False,\n",
        "            output_hidden_states=True,\n",
        "            return_dict_in_generate=True\n",
        "        )\n",
        "        output_sequences = t5_output.sequences\n",
        "        output_sequences = output_sequences[:, 1:].contiguous()\n",
        "        decoder_o = t5_output.decoder_hidden_states\n",
        "        decoder_o = [item[-1] for item in decoder_o]\n",
        "        decoder_o = torch.cat(decoder_o, dim=1)\n",
        "\n",
        "        output_sequences_mask1 = output_sequences != 0\n",
        "        output_sequences_mask2 = output_sequences != 1\n",
        "        output_sequences_mask = output_sequences_mask1 * output_sequences_mask2\n",
        "        output_sequences_mask = output_sequences_mask.long()\n",
        "        decoder_qo = torch.cat([encoder_q, decoder_o], dim=1)\n",
        "        output_sequences_mask = torch.cat([q_mask, output_sequences_mask], dim=1)\n",
        "        local_device = self.transformer_laryer_de.device\n",
        "        decoder_qo, _ = self.transformer_laryer_de(decoder_qo.to(local_device), output_sequences_mask.to(local_device))\n",
        "        output_sequences_mask_ex = output_sequences_mask.unsqueeze(dim=1)\n",
        "        output_sequences_mask_ex = output_sequences_mask_ex.expand(\n",
        "            [output_sequences_mask_ex.size(0), self.choice_num, output_sequences_mask_ex.size(-1)]).contiguous()\n",
        "        output_sequences_mask_ex = output_sequences_mask_ex.view(-1, output_sequences_mask.size(-1))\n",
        "        decoder_qo = decoder_qo.unsqueeze(dim=1)\n",
        "        decoder_qo = decoder_qo.expand(\n",
        "            [decoder_qo.size(0), self.choice_num, decoder_qo.size(-2), decoder_qo.size(-1)]).contiguous()\n",
        "        decoder_qo = decoder_qo.view(-1, decoder_qo.size(-2), decoder_qo.size(-1))\n",
        "        local_device = self.semantic_matching.device\n",
        "        semantic_vec, _, _ = self.semantic_matching(encoder_qo.to(local_device), decoder_qo.to(local_device),\n",
        "                                                    qo_mask.to(local_device), output_sequences_mask_ex.to(local_device))\n",
        "        local_device = self.option_linear.device\n",
        "        opt_score = self.option_linear(semantic_vec.to(local_device)).view(-1, self.choice_num)\n",
        "\n",
        "        return opt_score, output_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5be5b3",
      "metadata": {
        "papermill": {
          "duration": 0.005693,
          "end_time": "2024-03-13T04:34:49.565408",
          "exception": false,
          "start_time": "2024-03-13T04:34:49.559715",
          "status": "completed"
        },
        "tags": [],
        "id": "5c5be5b3"
      },
      "source": [
        "**run_genmc.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a139ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:49.578426Z",
          "iopub.status.busy": "2024-03-13T04:34:49.577964Z",
          "iopub.status.idle": "2024-03-13T04:34:49.661118Z",
          "shell.execute_reply": "2024-03-13T04:34:49.659906Z"
        },
        "papermill": {
          "duration": 0.092321,
          "end_time": "2024-03-13T04:34:49.663609",
          "exception": false,
          "start_time": "2024-03-13T04:34:49.571288",
          "status": "completed"
        },
        "tags": [],
        "id": "74a139ea",
        "outputId": "d6a0ce89-2fc3-4ece-9cc4-f3eeeced81f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "************Torch version: 2.1.2\n",
            "************Is CUDA enabled? True\n"
          ]
        }
      ],
      "source": [
        "# coding=utf-8\n",
        "from transformers import T5Tokenizer\n",
        "from tqdm import trange\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "#from utils import compute_rouges, save_dataset, read_dataset, set_seed, save_model\n",
        "#from model.modeling_genmc import GenMC\n",
        "import json\n",
        "import argparse\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "print(\"************Torch version:\",torch.__version__)\n",
        "print(\"************Is CUDA enabled?\",torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfd0868",
      "metadata": {
        "papermill": {
          "duration": 0.005969,
          "end_time": "2024-03-13T04:34:49.675931",
          "exception": false,
          "start_time": "2024-03-13T04:34:49.669962",
          "status": "completed"
        },
        "tags": [],
        "id": "cdfd0868"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583e1cc6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:49.689480Z",
          "iopub.status.busy": "2024-03-13T04:34:49.689150Z",
          "iopub.status.idle": "2024-03-13T04:34:49.715544Z",
          "shell.execute_reply": "2024-03-13T04:34:49.714698Z"
        },
        "papermill": {
          "duration": 0.035603,
          "end_time": "2024-03-13T04:34:49.717563",
          "exception": false,
          "start_time": "2024-03-13T04:34:49.681960",
          "status": "completed"
        },
        "tags": [],
        "id": "583e1cc6"
      },
      "outputs": [],
      "source": [
        "def get_input_feature(samples, max_source_length, max_len_gen, choice_num, external_sent_num=None):\n",
        "    sep = ' \\\\n '\n",
        "    output_clue = []\n",
        "    answers = []\n",
        "    input_ids_q, attention_mask_q = [], []\n",
        "    input_ids_qo, attention_mask_qo = [], []\n",
        "    input_clue_content_ids, attention_mask_clue_content = [], []\n",
        "    for sample in samples:\n",
        "        if 'answerKey' in sample:\n",
        "            answerKey = sample['answerKey']\n",
        "        else:\n",
        "            answerKey = \"A\"\n",
        "        question = sample['question']['stem']\n",
        "        while len(sample['question']['choices']) < choice_num:\n",
        "            sample['question']['choices'].append({\"text\": \"error\", \"para\": \"\", \"label\":chr(ord('A')+len(sample)-1)})\n",
        "\n",
        "        content_for_clue = \"\"\n",
        "        for o_i, (opt, opt_name) in enumerate(zip(sample['question']['choices'], 'ABCDEFGH'[:choice_num])):\n",
        "            option = opt['text']\n",
        "            content = \"\"\n",
        "            if external_sent_num is not None and 'para' in opt:\n",
        "                para = opt[\"para\"]\n",
        "                if isinstance(para, list):\n",
        "                    if len(para) > external_sent_num:\n",
        "                        #print(\"yes\")\n",
        "                        para = para[:external_sent_num]\n",
        "\n",
        "                    content = sep + \" \".join(para)\n",
        "                    if option == answerKey:\n",
        "                        print(\"hey\")\n",
        "                        content_for_clue = sep + \" \".join(para)\n",
        "                elif isinstance(para, str):\n",
        "                    para = para.split(\".\")\n",
        "                    if len(para) > external_sent_num:\n",
        "                        para = para[:external_sent_num]\n",
        "                    content = sep + \" \".join(para)\n",
        "                    if option == answerKey:\n",
        "                        print(\"hi\")\n",
        "                        content_for_clue = sep + \" \".join(para)\n",
        "                else:\n",
        "                    print('lack retrieval')\n",
        "                    # exit(0)\n",
        "            input_ids_qo.append(question + sep + option + content)\n",
        "\n",
        "\n",
        "        input_ids_q.append(question + sep)\n",
        "        input_clue_content_ids.append(question + sep + content_for_clue)\n",
        "\n",
        "        if answerKey in '123456':\n",
        "            answer = ord(answerKey) - ord('1')\n",
        "        else:\n",
        "            answer = ord(answerKey) - ord('A')\n",
        "        answers.append(answer)\n",
        "        output_clue.append(sample['question']['choices'][answer]['text'])\n",
        "\n",
        "    def tokenizer_fun(input_ids, max_len):\n",
        "        encoding = tokenizer(input_ids,\n",
        "                             padding='longest',\n",
        "                             max_length=max_len,\n",
        "                             truncation=True,\n",
        "                             return_tensors=\"pt\")\n",
        "        ids = encoding.input_ids.to(device)\n",
        "        mask = encoding.attention_mask.to(device)\n",
        "        return ids, mask\n",
        "\n",
        "    q_ids, q_mask = tokenizer_fun(input_ids_q, max_source_length)\n",
        "    qo_ids, qo_mask = tokenizer_fun(input_ids_qo, max_source_length)\n",
        "    clue_content_ids, clue_content_mask = tokenizer_fun(input_clue_content_ids, max_source_length)\n",
        "    clue_ids, _ = tokenizer_fun(output_clue, max_len_gen)\n",
        "    clue_ids = [\n",
        "        [(label if label != tokenizer.pad_token_id else -100) for label in labels_example] for labels_example in\n",
        "        clue_ids\n",
        "    ]\n",
        "    clue_ids = torch.tensor(clue_ids, dtype=torch.long).to(device)\n",
        "    answers = torch.tensor(answers, dtype=torch.long).to(device)\n",
        "    return q_ids, q_mask, qo_ids, qo_mask, clue_ids, clue_content_ids, clue_content_mask, answers, output_clue\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval(model, test_examples, tokenizer, eval_batch_size, choice_num, max_len, max_len_gen, external_sent_num):\n",
        "    count, count_right = 0, 0\n",
        "    results = []\n",
        "    model.eval()\n",
        "    step_count = len(test_examples) // eval_batch_size\n",
        "    if step_count * eval_batch_size < len(test_examples):\n",
        "        step_count += 1\n",
        "    step_trange = trange(step_count)\n",
        "    sources, targets = [], []\n",
        "    for step in step_trange:\n",
        "        beg_index = step * eval_batch_size\n",
        "        end_index = min((step + 1) * eval_batch_size, len(test_examples))\n",
        "        batch_example = [example for example in test_examples[beg_index:end_index]]\n",
        "        q_ids, q_mask, qo_ids, qo_mask, clue_ids, clue_content_ids, clue_content_mask, answers, output_clue = get_input_feature(batch_example,\n",
        "                                                                                           max_len, max_len_gen,\n",
        "                                                                                           args_choice_num,\n",
        "                                                                                           external_sent_num)\n",
        "        scores, output_sequences = model(q_ids, q_mask, qo_ids, qo_mask, choice_num)\n",
        "\n",
        "        scores = scores.cpu().detach().tolist()\n",
        "        answers = answers.cpu().detach().tolist()\n",
        "        p_anss = []\n",
        "        for p, a, example in zip(scores, answers, batch_example):\n",
        "            p_ans = p.index(max(p))\n",
        "            p_anss.append(example['question']['choices'][p_ans]['label'])\n",
        "            if p_ans == a:\n",
        "                count_right += 1\n",
        "            count += 1\n",
        "        for sample, p_ans in zip(batch_example, p_anss):\n",
        "            qid = sample['id']\n",
        "            results.append(qid + \",\" + p_ans)\n",
        "        predicts = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
        "        sources += predicts\n",
        "        targets += output_clue\n",
        "\n",
        "    rouge_score = compute_rouges(sources, targets)['rouge-l']\n",
        "\n",
        "    return count_right / count, rouge_score, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12befa4e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:49.731186Z",
          "iopub.status.busy": "2024-03-13T04:34:49.730871Z",
          "iopub.status.idle": "2024-03-13T04:34:49.734906Z",
          "shell.execute_reply": "2024-03-13T04:34:49.734043Z"
        },
        "papermill": {
          "duration": 0.013053,
          "end_time": "2024-03-13T04:34:49.736828",
          "exception": false,
          "start_time": "2024-03-13T04:34:49.723775",
          "status": "completed"
        },
        "tags": [],
        "id": "12befa4e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97576bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T04:34:49.751224Z",
          "iopub.status.busy": "2024-03-13T04:34:49.750943Z",
          "iopub.status.idle": "2024-03-13T13:11:29.099209Z",
          "shell.execute_reply": "2024-03-13T13:11:29.098271Z"
        },
        "papermill": {
          "duration": 30999.358164,
          "end_time": "2024-03-13T13:11:29.101353",
          "exception": false,
          "start_time": "2024-03-13T04:34:49.743189",
          "status": "completed"
        },
        "tags": [],
        "id": "b97576bd",
        "outputId": "3a1ded79-e02c-4365-c728-99b3ca64b72e",
        "colab": {
          "referenced_widgets": [
            "f33e4fac504242e186032ce52b731fd8",
            "ad20b5fee53d46909899f7d1df84bd06",
            "b2f62170c2b842498203da0e0381a027",
            "96eb0d21fc744b648c7014960ab29786",
            "1877093fb1d94e45abfa307498f68099"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f33e4fac504242e186032ce52b731fd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad20b5fee53d46909899f7d1df84bd06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2f62170c2b842498203da0e0381a027",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96eb0d21fc744b648c7014960ab29786",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1877093fb1d94e45abfa307498f68099",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1589: FutureWarning: `T5ForConditionalGeneration.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'encoder.block.0': 0, 'encoder.block.1': 1, ...}\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:930: FutureWarning: `T5Stack.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'block.0': 0, 'block.1': 1, ...}\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/63 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|| 63/63 [00:52<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_dev_acc: 0.27\n",
            "here2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:55<00:00,  1.54s/it,  Epoch:0 loss:4.5733]\n",
            "100%|| 620/620 [06:54<00:00,  1.50it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.7032479322170668\n",
            "dev_acc: 0.602\n",
            "new best dev acc: 0.602 rouge: 0.36728704276237256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:50<00:00,  1.53s/it,  Epoch:1 loss:4.1932]\n",
            "100%|| 620/620 [07:14<00:00,  1.43it/s]\n",
            "100%|| 63/63 [00:44<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.861206374823482\n",
            "dev_acc: 0.636\n",
            "new best dev acc: 0.636 rouge: 0.39037157080422336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:53<00:00,  1.54s/it,  Epoch:2 loss:3.8992]\n",
            "100%|| 620/620 [06:55<00:00,  1.49it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9626790397417793\n",
            "dev_acc: 0.652\n",
            "new best dev acc: 0.652 rouge: 0.37894958543705737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [16:03<00:00,  1.55s/it,  Epoch:3 loss:3.6429]\n",
            "100%|| 620/620 [06:58<00:00,  1.48it/s]\n",
            "100%|| 63/63 [00:44<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9852733508170264\n",
            "dev_acc: 0.65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:56<00:00,  1.54s/it,  Epoch:4 loss:3.4187]\n",
            "100%|| 620/620 [06:57<00:00,  1.49it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9931410127093\n",
            "dev_acc: 0.636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:54<00:00,  1.54s/it,  Epoch:5 loss:3.2227]\n",
            "100%|| 620/620 [06:56<00:00,  1.49it/s]\n",
            "100%|| 63/63 [00:44<00:00,  1.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9971757111155941\n",
            "dev_acc: 0.642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:51<00:00,  1.53s/it,  Epoch:6 loss:3.0482]\n",
            "100%|| 620/620 [06:59<00:00,  1.48it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9983861206374823\n",
            "dev_acc: 0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:48<00:00,  1.53s/it,  Epoch:7 loss:2.8881]\n",
            "100%|| 620/620 [06:47<00:00,  1.52it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9947548920718177\n",
            "dev_acc: 0.642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:43<00:00,  1.52s/it,  Epoch:8 loss:2.7425]\n",
            "100%|| 620/620 [06:49<00:00,  1.51it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9991930603187412\n",
            "dev_acc: 0.632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:47<00:00,  1.53s/it,  Epoch:9 loss:2.6076]\n",
            "100%|| 620/620 [06:53<00:00,  1.50it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9979826507968529\n",
            "dev_acc: 0.654\n",
            "new best dev acc: 0.654 rouge: 0.40058400970341546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:47<00:00,  1.53s/it,  Epoch:10 loss:2.4817]\n",
            "100%|| 620/620 [06:49<00:00,  1.51it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9989913253984265\n",
            "dev_acc: 0.634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:46<00:00,  1.53s/it,  Epoch:11 loss:2.3654]\n",
            "100%|| 620/620 [06:45<00:00,  1.53it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9989913253984265\n",
            "dev_acc: 0.66\n",
            "new best dev acc: 0.66 rouge: 0.4137962025780796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:42<00:00,  1.52s/it,  Epoch:12 loss:2.2568]\n",
            "100%|| 620/620 [06:47<00:00,  1.52it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9993947952390558\n",
            "dev_acc: 0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:40<00:00,  1.52s/it,  Epoch:13 loss:2.1557]\n",
            "100%|| 620/620 [06:47<00:00,  1.52it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9987895904781118\n",
            "dev_acc: 0.622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:43<00:00,  1.52s/it,  Epoch:14 loss:2.0603]\n",
            "100%|| 620/620 [06:51<00:00,  1.51it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9995965301593706\n",
            "dev_acc: 0.654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:39<00:00,  1.52s/it,  Epoch:15 loss:1.9708]\n",
            "100%|| 620/620 [06:48<00:00,  1.52it/s]\n",
            "100%|| 63/63 [00:43<00:00,  1.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9991930603187412\n",
            "dev_acc: 0.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:43<00:00,  1.52s/it,  Epoch:16 loss:1.887]\n",
            "100%|| 620/620 [06:50<00:00,  1.51it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9993947952390558\n",
            "dev_acc: 0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:42<00:00,  1.52s/it,  Epoch:17 loss:1.8092]\n",
            "100%|| 620/620 [06:49<00:00,  1.52it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9989913253984265\n",
            "dev_acc: 0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:43<00:00,  1.52s/it,  Epoch:18 loss:1.7359]\n",
            "100%|| 620/620 [06:47<00:00,  1.52it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9997982650796853\n",
            "dev_acc: 0.634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:41<00:00,  1.52s/it,  Epoch:19 loss:1.6671]\n",
            "100%|| 620/620 [06:46<00:00,  1.53it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9997982650796853\n",
            "dev_acc: 0.642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:35<00:00,  1.51s/it,  Epoch:20 loss:1.6033]\n",
            "100%|| 620/620 [06:46<00:00,  1.53it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9993947952390558\n",
            "dev_acc: 0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 620/620 [15:33<00:00,  1.50s/it,  Epoch:21 loss:1.543]\n",
            "100%|| 620/620 [06:45<00:00,  1.53it/s]\n",
            "100%|| 63/63 [00:42<00:00,  1.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc 0.9995965301593706\n",
            "dev_acc: 0.628\n",
            "best dev acc: 0.66 best_dev_rouge_score: 0.4137962025780796\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = 'arc_challenge'\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    args_model_path = 't5-base'\n",
        "    args_choice_num = 4\n",
        "    args_train_batch_size = 8 # total batch size for training\n",
        "    args_eval_batch_size = 8 # total batch size for eval\n",
        "    args_gradient_accumulation_steps = 1 # Number of updates steps to accumulate before performing a backward/update pass\n",
        "    args_max_len = 256\n",
        "    args_max_len_gen = 64\n",
        "    args_lr = 1e-4\n",
        "    args_epoch_num = 30\n",
        "    args_num_hidden_layers = 1\n",
        "    args_alpha = 0.5\n",
        "    args_beta = 1\n",
        "    args_seed = 1\n",
        "    args_external_sent_num = 10\n",
        "    args_gpu = \"0\"\n",
        "\n",
        "   # args = parser.parse_args()\n",
        "    file_name = f'lr_{args_lr}_seed_{args_seed}_bs_{args_train_batch_size}_ga_{args_gradient_accumulation_steps}_layer_num_{args_num_hidden_layers}_alpha_{args_alpha}_beta_{args_beta}'\n",
        "    output_model_path = './outputs/' + file_name + \"/\"\n",
        "    path_save_result = './results/' + file_name + \"/\"\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args_gpu\n",
        "    os.makedirs(path_save_result, exist_ok=True)\n",
        "    set_seed(args_seed)\n",
        "    train_examples = read_dataset(\"/kaggle/input/openbkqa/train.jsonl\")\n",
        "    dev_examples = read_dataset(\"/kaggle/input/openbkqa/dev.jsonl\")\n",
        "    test_examples = read_dataset(\"/kaggle/input/openbkqa/test.jsonl\")\n",
        "\n",
        "#     print(json.dumps({\"lr\": args.lr, \"model\": args.model_path, \"seed\": args.seed,\n",
        "#                       \"bs\": args.train_batch_size,\n",
        "#                       'gradient_accumulation_steps': args.gradient_accumulation_steps,\n",
        "#                       \"epoch\": args.epoch_num,\n",
        "#                       \"train_path\": args.data_path_train,\n",
        "#                       \"dev_path\": args.data_path_dev,\n",
        "#                       \"test_path\": args.data_path_test,\n",
        "#                       \"train_size\": len(train_examples),\n",
        "#                       \"dev_size\": len(dev_examples),\n",
        "#                       \"test_size\": len(test_examples),\n",
        "#                       'num_hidden_layers': args.num_hidden_layers,\n",
        "#                       'external_sent_num': args.external_sent_num,\n",
        "#                       \"alpha\": args.alpha, \"beta\": args.beta}, indent=2))\n",
        "\n",
        "    train_batch_size = args_train_batch_size // args_gradient_accumulation_steps\n",
        "    tokenizer = T5Tokenizer.from_pretrained(args_model_path)\n",
        "    model = GenMC(args_model_path, args_num_hidden_layers, args_alpha, args_beta)\n",
        "\n",
        "\n",
        "   # checkpoint = torch.load(\"/kaggle/input/checkpoints/checkpointspytorch_model.bin\", map_location='cpu')\n",
        "   # model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "#     if args.init_checkpoint is not None:\n",
        "#         checkpoint = torch.load(args.init_checkpoint, map_location='cpu')\n",
        "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=args_lr, weight_decay=0.01)\n",
        "\n",
        "    step_count, step_all, early_stop = 0, 0, 0\n",
        "    best_dev_rouge_score, best_test_rouge_score = 0, 0\n",
        "    tr_loss, nb_tr_steps = 0, 0\n",
        "    print(\"here1\")\n",
        "    best_dev_acc, _, _ = eval(model, dev_examples, tokenizer, args_eval_batch_size, args_choice_num, args_max_len,\n",
        "                              args_max_len_gen, args_external_sent_num)\n",
        "    print('best_dev_acc:',best_dev_acc)\n",
        "    best_test_acc = 0\n",
        "\n",
        "    print(\"here2\")\n",
        "    log = []\n",
        "    x = []\n",
        "    y_dev = []\n",
        "    y_train = []\n",
        "\n",
        "    for epoch in range(args_epoch_num):\n",
        "        x.append(epoch)\n",
        "        early_stop += 1\n",
        "        order = list(range(len(train_examples)))\n",
        "        random.seed(args_seed + epoch)\n",
        "        random.shuffle(order)\n",
        "        model.train()\n",
        "        step_count = len(train_examples) // train_batch_size\n",
        "        if step_count * train_batch_size < len(train_examples):\n",
        "            step_count += 1\n",
        "        step_trange = trange(step_count)\n",
        "        for step in step_trange:\n",
        "            step_all += 1\n",
        "            beg_index = step * train_batch_size\n",
        "            end_index = min((step + 1) * train_batch_size, len(train_examples))\n",
        "            order_index = order[beg_index:end_index]\n",
        "            batch_example = [train_examples[index] for index in order_index]\n",
        "            q_ids, q_mask, qo_ids, qo_mask, clue_ids, clue_content_ids, clue_content_mask, answers, output_clue = get_input_feature(\n",
        "                batch_example,\n",
        "                max_source_length=args_max_len,\n",
        "                max_len_gen=args_max_len_gen,\n",
        "                choice_num=args_choice_num,\n",
        "                external_sent_num=args_external_sent_num)\n",
        "            loss = model(q_ids, q_mask, qo_ids, qo_mask, args_choice_num, clue_ids, clue_content_ids, clue_content_mask, answers)\n",
        "\n",
        "            loss = loss.mean()\n",
        "            log.append(loss.item())\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_steps += 1\n",
        "            loss = loss / args_gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "            if (step + 1) % args_gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                # scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            loss_show = ' Epoch:' + str(epoch) + \" loss:\" + str(round(tr_loss / nb_tr_steps, 4))\n",
        "            step_trange.set_postfix_str(loss_show)\n",
        "\n",
        "        train_acc, train_rouge_score, results_dev = eval(model, train_examples, tokenizer, args_eval_batch_size,\n",
        "                                                     args_choice_num, args_max_len, args_max_len_gen,\n",
        "                                                     args_external_sent_num)\n",
        "\n",
        "        dev_acc, dev_rouge_score, results_dev = eval(model, dev_examples, tokenizer, args_eval_batch_size,\n",
        "                                                     args_choice_num, args_max_len, args_max_len_gen,\n",
        "                                                     args_external_sent_num)\n",
        "        print('train_acc', train_acc)\n",
        "        print('dev_acc:', dev_acc)\n",
        "        y_dev.append(dev_acc)\n",
        "        y_train.append(train_acc)\n",
        "\n",
        "        if dev_acc > best_dev_acc:\n",
        "            save_dataset(path_save_result + '/dev.csv', results_dev)\n",
        "            early_stop = 0\n",
        "            #test_acc, test_rouge_score, results_test = eval(model, test_examples, tokenizer, args_eval_batch_size,\n",
        "                                                            #args_choice_num, args_max_len, args_max_len_gen,\n",
        "                                                            #args_external_sent_num)\n",
        "\n",
        "            #save_dataset(path_save_result + '/test.csv', results_test)\n",
        "            #best_dev_acc, best_test_acc, best_dev_rouge_score, best_test_rouge_score = dev_acc, test_acc, dev_rouge_score, test_rouge_score\n",
        "            best_dev_acc,best_dev_rouge_score = dev_acc, dev_rouge_score\n",
        "\n",
        "            save_model('./checkpoints', model, optimizer)\n",
        "            print('new best dev acc:', dev_acc, 'rouge:', dev_rouge_score)\n",
        "\n",
        "        if early_stop >= 10:\n",
        "            break\n",
        "\n",
        "    print('best dev acc:', best_dev_acc,\n",
        "          'best_dev_rouge_score:', best_dev_rouge_score)\n",
        "    plt.plot(log)\n",
        "    plt.xlabel('step')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbd8fd4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-13T13:11:36.186475Z",
          "iopub.status.busy": "2024-03-13T13:11:36.186111Z",
          "iopub.status.idle": "2024-03-13T13:11:36.446309Z",
          "shell.execute_reply": "2024-03-13T13:11:36.445399Z"
        },
        "papermill": {
          "duration": 3.813233,
          "end_time": "2024-03-13T13:11:36.448238",
          "exception": false,
          "start_time": "2024-03-13T13:11:32.635005",
          "status": "completed"
        },
        "tags": [],
        "id": "5fbd8fd4",
        "outputId": "fe4e2be6-6ff6-48c4-bf28-d847f8adc3e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "l1 = plt.plot(x, y_dev, label = 'training loss')\n",
        "l2 = plt.plot(x, y_train, label = 'validation loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4545841,
          "sourceId": 7770550,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4563909,
          "sourceId": 7795659,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 31037.243763,
      "end_time": "2024-03-13T13:11:42.578122",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-03-13T04:34:25.334359",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}